{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import Tasks2\n",
    "import NGRAMS\n",
    "final_data = Tasks2.final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# NATURAL LANGUAGE PROCESSING\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "# COUNTER CLASS\n",
    "from collections import Counter\n",
    "\n",
    "# SCIKIT LEARN\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# VISUALISATION\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import wordcloud\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import random\n",
    "\n",
    "# ELSE\n",
    "from itertools import izip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# stemmer = PorterStemmer().stem\n",
    "# tokenize = nltk.word_tokenize\n",
    "\n",
    "# def stem(tokens,stemmer = PorterStemmer().stem):\n",
    "#     return [stemmer(w.lower()) for w in tokens] \n",
    "\n",
    "# def lemmatize(text):\n",
    "#     \"\"\"\n",
    "#     Extract simple lemmas based on tokenization and stemming\n",
    "#     Input: string\n",
    "#     Output: list of strings (lemmata)\n",
    "#     \"\"\"\n",
    "#     return stem(tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from NGRAMS import corpus_raw_split, corpus_raw, song_words_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lexical_tags = [\"ADJ\", \"ADV\", \"NOUN\", \"VERB\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tagged_songs = [nltk.pos_tag(song_words, \"universal\") for song_words in song_words_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lexical_density_list = [float(len([word[0] for word in song if word[1] in lexical_tags]))/float(len(song)) for song in tagged_songs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seconds_list = [float(length/float(1000)) for length in final_data[\"songLength\"]]\n",
    "words_per_song = [float(len(song)) for song in song_words_list]\n",
    "lyrical_density_list = [words/second for words, second in zip(words_per_song, seconds_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#content_density_list = [x + y for x, y in zip(lyrical_density_list, lexical_density_list)]\n",
    "# Except not really. Content density will be represented by graphing lexical vs lyrical density\n",
    "# Or maybe we could also 3d plots, with lex, lyr, and time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lexical_words_in_songs = [[word[0] for word in song if word[1] in lexical_tags] for song in tagged_songs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lexical_words_in_songs_no_stopwords = [[word for word in song if not word in STOPWORDS] for song in lexical_words_in_songs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
